{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# VAPr Quick-Start Guide\n",
    "\n",
    "#### Authors: C. Mazzaferro, A. Birmingham, Kathleen Fisch\n",
    "#### Contact Email: kfisch@ucsd.edu\n",
    "#### Last Update: February 2017\n",
    " \n",
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Installation](#Installation)\n",
    "    * [Python 3 and MongoDB](#Python-3-and-MongoDB)\n",
    "    * [ANNOVAR](#ANNOVAR)\n",
    "    * [VAPr](#VAPr)\n",
    "    * [Dataset Downloads](#Dataset-Downloads)\n",
    "* [Usage](#Usage)\n",
    "    * [Novel Variant Annotation](#Novel-Variant-Annotation)\n",
    "    * [Known Variant Annotation and Storage](#Known-Variant-Annotation-and-Storage)\n",
    "    * [Variant Prioritization](#Variant-Prioritization)\n",
    "    * [File Export](#File-Export)\n",
    "* [Citations](#Citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook walks through the steps of annotating variants from a VCF efficiently and thoroughly using the package VAPr. The package retrieves variant information from [ANNOVAR](http://annovar.openbioinformatics.org/en/latest/) and [myvariant.info](myvariant.info) and consolidates it into a single local database for ease of use in investigating and filtering variant findings.\n",
    "\n",
    "For a more complete description of the functionalities of the package, you can visit the [VAPr Sample Usage Notebook](https://github.com/ucsd-ccbb/VAPr/blob/master/VAPr%20Sample%20Usage.ipynb) and/or check the full documentation on GitHub. \n",
    "\n",
    "*Note to reviewers*: this notebook is in all its functionalities the same as the one in the official documentation (https://github.com/ucsd-ccbb/VAPr/blob/master/VAPr%20Quick-Start%20Guide.ipynb). We have added some notes here regarding performance and regarding the file structure of this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "VAPr requires a Python 3 environment with the pandas library and MongoDB installed.  Here, we provide instructions for how to set up such an environment using  `conda`, a cross-platform package and environment manager.  (If you wish to follow this approach but do not already have either the full or minimal version of `conda` (`Anaconda` or `miniconda`, respectively) installed on your system, visit [https://conda.io/docs/get-started.html](https://conda.io/docs/get-started.html) to decide which is right for you and then follow the instructions provided there to install it.)\n",
    "\n",
    "### Python 3 and MongoDB\n",
    "\n",
    "VAPr is written in Python 3, and stores variant annotations in NoSQL database, using a locally-installed instance of MongoDB.  If you wish to run the Jupyter notebooks provided with VAPr locally, it is also necessary to have a local Jupyter notebook server installed. To set up these requirements in your machine's default environment using `conda`, run the following command:\n",
    "\n",
    "    conda install python=3 pandas mongodb pymongo jupyter notebook\n",
    "\n",
    "MongoDB also needs a location to store its data, so create a directory for this in the location of your choice, e.g.:\n",
    "\n",
    "    mkdir -p /Temp/MongoDbData\n",
    "    \n",
    "(or, on Windows systems, `md /Temp/MongoDbData`). \n",
    "\n",
    "Then start the MongoDb with the command\n",
    "\n",
    "    mongod --dbpath /Temp/MongoDbData\n",
    "\n",
    "    \n",
    "To check if mongodb is currently running, run:\n",
    "\n",
    "    service mongod status\n",
    "    \n",
    "which should return    \n",
    "    \n",
    "    mongod (pid 591) is running...\n",
    "    \n",
    "519 is the process number so it may differ every time it is run. In case it is not running, the command will return:\n",
    "\n",
    "    mongod dead but subsys locked\n",
    "    \n",
    "    \n",
    "### VAPr\n",
    "\n",
    "VAPr is available from PyPi.  Once the above requirements have been installed, VAPr itself can be installed by just running:\n",
    "\n",
    "    pip install VAPr\n",
    "\n",
    "\n",
    "### ANNOVAR\n",
    "(It is possible to proceed without installing ANNOVAR. In that case, the variants that will be annotated and sent ot Mongo are the ones found in MyVariant.info. In that case, users can skip the next steps and go straight to the section **Known Variant Annotation and Storage**)\n",
    "\n",
    "\n",
    "Users who wish to annotate novel variants will also need to have a local installation of the popular command-line software ANNOVAR([1](#Citations)), which VAPr wraps with a Python interface.  If you use ANNOVAR's functionality through VAPr, please remember to cite the ANNOVAR publication (see #1 in [Citations](#Citations))!\n",
    "\n",
    "The base ANNOVAR program must be installed by each user individually, since its license agreement does not permit redistribution.  Please visit the ANNOVAR download form at [http://www.openbioinformatics.org/annovar/annovar_download_form.php](http://www.openbioinformatics.org/annovar/annovar_download_form.php), ensure that you meet the requirements for a free license, and fill out the required form.  You will then receive an email providing a link to the latest ANNOVAR release file.  Download this file (which will usually have a name like `annovar.latest.tar.gz`) and place it in the location on your machine in which you would like the ANNOVAR program and its data to be installed--the entire disk size of the databases will be around 25 GB, so make sure you have such space available!  Record the complete path to this location in the `ANNOVAR_PATH` variable below so that VAPr will know where to access it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: You MUST fill in this variable with the location of ANNOVAR *on your system* \n",
    "ANNOVAR_PATH = # e.g., /User/Me/Applications/annovar/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if execution of the above cell caused a syntax error, you have probably forgotten to fill in the path to ANNOVAR on your system; please add that information to the above cell and run it again!\n",
    "\n",
    "Then simply extract the ANNOVAR tar.gz file in that location to complete the software installation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Downloads\n",
    "\n",
    "ANNOVAR requires a number of external data files containing annotation information.  VAPr provides wrapper functions that automatically download these data files and, when desired, update them. The data sources currently supported by default are:\n",
    " \n",
    "- knownGene\n",
    "- tfbsConsSites\n",
    "- cytoBand\n",
    "- genomicSuperDups\n",
    "- esp6500siv2_all\n",
    "- 1000g2015aug_all\n",
    "- popfreq_all\n",
    "- clinvar_20140929\n",
    "- cosmic70\n",
    "- nci60\n",
    "\n",
    "These can be expanded or restricted by the user, depending on his or her research needs. \n",
    "\n",
    "The simple Python code below downloads and installs the necessary databases for ANNOVAR. It currently supports the three different genome builds, `hg19`, `hg18`, `hg38`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src import base, parsers\n",
    "import importlib\n",
    "importlib.reload(base)\n",
    "importlib.reload(parsers)\n",
    "\n",
    "# Directory of input files to be annotated\n",
    "IN_PATH = \"/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/small_files/\"\n",
    "\n",
    "# Output file directory\n",
    "OUT_PATH = \"/Volumes/Carlo_HD1/CCBB/VAPr_files/csv_files/small_samples/\"\n",
    "\n",
    "# Location of your annovar download. The folder should contain the following files/directories:\n",
    "ANNOVAR_PATH = '/Volumes/Carlo_HD1/CCBB/annovar/'  \n",
    "\n",
    "\n",
    "# Design File (optional)\n",
    "design_file = '/Volumes/Carlo_HD1/CCBB/VAPr_files/des_file.csv'\n",
    "\n",
    "# Database and Collection names (optional)\n",
    "proj_data = {'db_name': 'VariantDatabase',\n",
    "            'project_name': 'collect'}\n",
    "\n",
    "\n",
    "Project = base.AnnotationProject(IN_PATH, \n",
    "                                 OUT_PATH, \n",
    "                                 ANNOVAR_PATH, \n",
    "                                 proj_data, \n",
    "                                 design_file=design_file, \n",
    "                                 build_ver='hg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Normal_targeted_seq', '/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/small_files/Normal_targeted_seq.vcf', '/Volumes/Carlo_HD1/CCBB/VAPr_files/csv_files/small_samples/Normal_targeted_seq_annotated.hg19_multianno.txt'), ('Mutect_Pass_Filtered_tumor', '/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/small_files/Mutect_Pass_Filtered_tumor.vcf', '/Volumes/Carlo_HD1/CCBB/VAPr_files/csv_files/small_samples/Mutect_Pass_Filtered_tumor_annotated.hg19_multianno.txt')]\n",
      "950\n",
      "querying 1-1...querying 1-1...INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): myvariant.info\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): myvariant.info\n",
      "952\n",
      "querying 1-1...querying 1-1...INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): myvariant.info\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): myvariant.info\n",
      "done.\n",
      "done.\n",
      "done.\n",
      "done.\n",
      "['chr', 'start', 'end', 'ref', 'alt', 'popfreqmax', '1000g_all', '1000g_afr', '1000g_amr', '1000g_eas', '1000g_eur', '1000g_sas', 'exac_all', 'exac_afr', 'exac_amr', 'exac_eas', 'exac_fin', 'exac_nfe', 'exac_oth', 'exac_sas', 'esp6500siv2_all', 'esp6500siv2_aa', 'esp6500siv2_ea', 'cg46', 'clinsig', 'clndbn', 'clnacc', 'clndsdb', 'clndsdbid', 'cytoband', 'esp6500siv2_all', 'nci60', 'targetscans', '1000g2015aug_all', 'genomicsuperdups', 'func_knowngene', 'gene_knowngene', 'genedetail_knowngene', 'exonicfunc_knowngene', 'aachange_knowngene', 'tfbsconssites', 'cosmic70', 'otherinfo']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized format string: GT:AD:BQ:DP:FA:SS",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/parsers.py\", line 253, in _variant_parsing\n    csv_variants = csv_parsing.open_and_parse_chunks(self.step, build_ver=self.buildver, offset=offset)\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/models.py\", line 115, in open_and_parse_chunks\n    listofdicts.append(modeled.final_dict)\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/models.py\", line 138, in __init__\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/models.py\", line 162, in process\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/models.py\", line 169, in parse_genotype\n    gen_dic = {'genotype': genotype_to_fill.genotype,\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/vcf_parsing.py\", line 202, in parse\n    raise ValueError(\"Unrecognized format string: {0}\".format(format_string))\nValueError: Unrecognized format string: GT:AD:BQ:DP:FA:SS\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a58682ee4344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mProject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_annotation_and_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/base.py\u001b[0m in \u001b[0;36mparallel_annotation_and_saving\u001b[0;34m(self, n_processes)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_annotation_and_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;34m\"\"\" Wrapper around parallel annotation multiprocess runner  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotator_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/parsers.py\u001b[0m in \u001b[0;36mparallel_annotation\u001b[0;34m(self, n_processes)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m#print(mapping[0]['Normal_targeted_seq'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_parsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_tupls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_variant_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/src/parsers.py\u001b[0m in \u001b[0;36mpooling\u001b[0;34m(n_processes, input_1, input_2)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized format string: GT:AD:BQ:DP:FA:SS"
     ],
     "output_type": "error"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr', 'start', 'end', 'ref', 'alt', 'popfreqmax', '1000g_all', '1000g_afr', '1000g_amr', '1000g_eas', '1000g_eur', '1000g_sas', 'exac_all', 'exac_afr', 'exac_amr', 'exac_eas', 'exac_fin', 'exac_nfe', 'exac_oth', 'exac_sas', 'esp6500siv2_all', 'esp6500siv2_aa', 'esp6500siv2_ea', 'cg46', 'clinsig', 'clndbn', 'clnacc', 'clndsdb', 'clndsdbid', 'cytoband', 'esp6500siv2_all', 'nci60', 'targetscans', '1000g2015aug_all', 'genomicsuperdups', 'func_knowngene', 'gene_knowngene', 'genedetail_knowngene', 'exonicfunc_knowngene', 'aachange_knowngene', 'tfbsconssites', 'cosmic70', 'otherinfo']\n"
     ]
    }
   ],
   "source": [
    "Project.parallel_annotation_and_saving(n_processes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mutect_Pass_Filtered_tumor': {'Condition': 'BD_lithium_responder',\n",
       "  'Patient': 'JNJ005',\n",
       "  'Sample_Name2': 'sample3',\n",
       "  'Tissue': 'lymphoblast',\n",
       "  'Treatment': 'Li',\n",
       "  'libType': 'singleend'},\n",
       " 'Normal_targeted_seq': {'Condition': 'BD_lithium_responder',\n",
       "  'Patient': 'JNJ005',\n",
       "  'Sample_Name2': 'sample2',\n",
       "  'Tissue': 'lymphoblast',\n",
       "  'Treatment': 'VPA',\n",
       "  'libType': 'singleend'}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.read_csv(design_file).set_index('Sample').T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "Project.parallel_annotation_and_saving(n_processes=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowloading the files is usually fairly fast, but uncompressing them takes some time. To check the status, run the next command and make sure all files are in .txt and .idx format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x1062940f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, os\n",
    "subprocess.Popen(['open', os.path.join(ANNOVAR_PATH, 'humandb')], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### Novel Variant Annotation\n",
    "\n",
    "Variant-calling pipelines often identify novel variants that have not been annotated in existing data sources. VAPr encourages (but does not require) the use of ANNOVAR to assign even these novel variants minimal annotation such as predicted mutation type.  Such primary annotation can be run through VAPr as shown in the below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get an estimate of the number of variants in the vcf file\n",
    "print(\"Number of variants in vcf file: %i\" % sum(1 for line in open(IN_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Project.run_annovar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~2 minutes for 26k variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the screen output of `run_annovar` includes a statement like the following:\n",
    "\n",
    "    Annovar finished working on file : test_file_one_annotated.A.txt file has been created in the OUT_PATH directory\n",
    "    \n",
    "This file name and path will be used in the next step.\n",
    "\n",
    "### Known Variant Annotation and Storage\n",
    "\n",
    "Most often, researchers are primarily interested in variants about which some information is already available (such as population frequency or disease association).  VAPr utilizes the MyVariant.info web service ([2](#Citations)) to identify up-to-date annotation information from more than a dozen sources for such known variants; the resulting annotations are then stored to the local MongoDB database.  If additional annotations should be included--such as those generated by ANNOVAR for novel variants--these can be provided as a CSV-formatted file.  \n",
    "\n",
    "To attach known annotations to variants and store them to the local database, it is only necessary to provide three pieces of information:\n",
    " 1. The path to the VCF file containing the variants to be annotated and stored\n",
    " 2. The name of the MongoDB database to which the variants will be stored.  Note that this database need not be created ahead of time by the user: if a database of the input name does not exist, VAPr will automatically create one.\n",
    " 3. The name of the MongoDB collection to which the variants will be stored.  As for the database, this collection need not pre-exist, since VAPr will automatically create it if necessary.\n",
    " \n",
    "Optionally, the user may also provide the path to a CSV file containing additional annotations to be stored. These are the annotations that would be retrieved by annovar. If the argument `annotated_file=csv_file` is not provided, then the package only gets variants from MyVariant.Info\n",
    "\n",
    "Below is an example of the simple Python required to annotate and store variants, including novel variant annotations produced earlier with ANNOVAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-45250821d8a6>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-45250821d8a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    vcf_file = # e.g., '/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/not_annotated/Normal_targeted_seq.vcf'\u001b[0m\n\u001b[0m                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vcf_file = # e.g., '/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/not_annotated/Normal_targeted_seq.vcf'\n",
    "csv_file = # e.g., '/Volumes/Carlo_HD1/CCBB/VAPr_files/csv_files/Normal_targeted_seq_annotated.hg19_multianno.txt'\n",
    "\n",
    "project_data= {'db_name': 'VariantDatabase', \n",
    "               'project_name': 'my_project',  # All variants are stored to a collection named as the project name\n",
    "               'patient_id': 'patient_1',\n",
    "               'sample_id': 'sample_1'\n",
    "               }\n",
    "\n",
    "pars = parser_models.VariantParsing(vcf_file, project_data, annotated_file=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'VAPr'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dcf2129d08ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mVAPr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannovar_suprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'VAPr'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import importlib\n",
    "from VAPr import parser_models, annovar_suprocess\n",
    "importlib.reload(parser_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from VAPr import parser_models, annovar_suprocess\n",
    "importlib.reload(parser_models)\n",
    "\n",
    "IN_PATH = '/Volumes/Carlo_HD1/CCBB/VAPr_files/vcf_files/not_annotated/'\n",
    "OUT_PATH = '/Volumes/Carlo_HD1/CCBB/VAPr_files/csv_parallel/'\n",
    "\n",
    "project_data= {'db_name': 'VariantDatabase', \n",
    "               'project_name': 'my_project',  # All variants are stored to a collection named as the project name\n",
    "               'patient_id': 'patient_1',\n",
    "               'sample_id': 'sample_1'\n",
    "               }\n",
    "\n",
    "pars = parser_models.MultiThreadedParsing(IN_PATH, project_data, OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-950...done.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized format string: GT:AD:BQ:DP:FA:SS",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\", line 215, in _variant_parsing\n    csv_variants = csv_parsing.open_and_parse_chunks(self.step, build_ver=self.buildver, offset=offset)\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\", line 349, in open_and_parse_chunks\n    modeled = AnnovarModels(dict_filled)\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\", line 372, in __init__\n    self.final_dict = self.process()\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\", line 396, in process\n    self.dictionary['genotype'] = self.parse_genotype()\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\", line 403, in parse_genotype\n    genotype_to_fill = parser.parse(self.dictionary['otherinfo'][0], self.dictionary['otherinfo'][1])\n  File \"/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/vcf_parsing.py\", line 201, in parse\n    raise ValueError(\"Unrecognized format string: {0}\".format(format_string))\nValueError: Unrecognized format string: GT:AD:BQ:DP:FA:SS\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1bbf28d24709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_variant_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\u001b[0m in \u001b[0;36mparallel_variant_parsing\u001b[0;34m(self, n_processes)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_variant_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_parsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_variant_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/Documents/CCBB/ucsd-ccbb/VAPr/VAPr/parser_models.py\u001b[0m in \u001b[0;36mpooling\u001b[0;34m(n_processes, input_1, input_2)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized format string: GT:AD:BQ:DP:FA:SS"
     ],
     "output_type": "error"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-952...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-960...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-952...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-957...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-954...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-955...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-957...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-956...done.\n",
      "querying 1-951...done.\n",
      "querying 1-961...done.\n",
      "querying 1-957...done.\n",
      "querying 1-950...done.\n",
      "querying 1-953...done.\n",
      "querying 1-950...done.\n",
      "querying 1-955...done.\n",
      "querying 1-950...done.\n",
      "querying 1-956...done.\n",
      "querying 1-950...done.\n",
      "querying 1-952...done.\n",
      "querying 1-951...done.\n",
      "querying 1-957...done.\n",
      "querying 1-951...done.\n",
      "querying 1-955...done.\n",
      "querying 1-954...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-956...done.\n",
      "querying 1-950...done.\n",
      "querying 1-962...done.\n",
      "querying 1-950...done.\n",
      "querying 1-953...done.\n",
      "querying 1-950...done.\n",
      "querying 1-956...done.\n",
      "querying 1-951...done.\n",
      "querying 1-956...done.\n",
      "querying 1-955...done.\n",
      "querying 1-950...done.\n",
      "querying 1-953...done.\n",
      "querying 1-950...done.\n",
      "querying 1-962...done.\n",
      "querying 1-950...done.\n",
      "querying 1-856...done.\n",
      "Parsing Buffer...\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-954...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "Parsing Buffer...\n",
      "querying 1-950...done.\n",
      "querying 1-952...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-952...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-952...done.\n",
      "querying 1-951...done.\n",
      "querying 1-955...done.\n",
      "querying 1-956...done.\n",
      "querying 1-951...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-950...done.\n",
      "querying 1-951...done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-23:\n"
     ]
    }
   ],
   "source": [
    "pars.parallel_variant_parsing(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotate_and_save\n",
    "\n",
    "\n",
    "The main method of the package is `annotate_and_save`. It will take care of grabbing your variants from a vcf file, extracting the HGVS IDs, pulling the variants from MyVariant.info and sending them to mongo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "pars.annotate_and_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~3 minutes for 25k variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great introduction to the concepts relevant to MongoDB, and specifically how to interact with it using python can be found [here](https://docs.mongodb.com/getting-started/python/introduction/). Of particular interest is the explanation on how documents are formatted and stored inside a the database. Variants will follow that format as well: a sample entry of the database will look roughly as follows (the document for this variant (HGVS_id: chr20:g.25194768A>G) has been reduced to half of its actual size). \n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"_id\": ObjectId(\"5887c6d3bc644e51c028971a\"),\n",
    "  \"chr\": \"chr19\",\n",
    "  \"cytoband\": {\n",
    "    \"Region\": \"13\",\n",
    "    \"Sub_Band\": \"41\",\n",
    "    \"Chromosome\": 19,\n",
    "    \"Band\": \"q\",\n",
    "    \"Name\": \"19q13.41\"\n",
    "  },\n",
    "  \"alt\": \"C\",\n",
    "  \"hg19\": {\n",
    "    \"end\": 25194768,\n",
    "    \"start\": 25194768\n",
    "  },\n",
    "  \n",
    "  ...\n",
    "  \n",
    "  \"otherinfo\": [\n",
    "    \"GT:AD:DP:GQ:PL\",\n",
    "    \"1/1:0,2:2:6:89,6,0\"\n",
    "  ],\n",
    "  \"hgvs_id\": \"chr20:g.25194768A>G\",\n",
    "  \"esp6500siv2_all\": \"0.71\",\n",
    "  \"ref\": \"T\",\n",
    "  \"chrom\": \"20\",\n",
    "  \"grasp\": {\n",
    "    \"exclusively_male_female\": \"n\",\n",
    "    \"initial_sample_description\": [\n",
    "      \"Up to 46186 EA individuals\",\n",
    "      [\n",
    "        \"Up to 3445 EA cases\",\n",
    "        \" 6935 EA controls\"\n",
    "      ],\n",
    "      \"69395 EA individuals\",\n",
    "      \"69395 EA individuals\"\n",
    "    ],\n",
    "    \"creation_date\": \"8/17/12\",\n",
    "    \"gwas_ancestry_description\": \"European\",\n",
    "    \"srsid\": 6083780,\n",
    "    \"platform_snps_passing_qc\": [\n",
    "      \"Affymetrix & Illumina [~2.5 million] (imputed)\",\n",
    "      \"Illumina [528745]\",\n",
    "      [\n",
    "        \"Affymetrix\",\n",
    "        \" Illumina & Perlegen [~2.5 million] (imputed)\"\n",
    "      ],\n",
    "      [\n",
    "        \"Affymetrix\",\n",
    "        \" Illumina & Perlegen [~2.5 million] (imputed)\"\n",
    "      ]\n",
    "    ],\n",
    "    \"hg19\": {\n",
    "      \"chr\": 20,\n",
    "      \"pos\": 25194768\n",
    "    },\n",
    "    \"publication\": [\n",
    "      {\n",
    "        \"pmid\": 20081858,\n",
    "        \"phenotype\": \"HOMA-B\",\n",
    "        \"p_value\": 0.033930000000000001825,\n",
    "        \"snpid\": \"rs6083780\",\n",
    "        \"paper_phenotype_description\": [\n",
    "          \"Glucose homeostasis traits (fasting glucose\",\n",
    "          \" fasting insulin\",\n",
    "          \" HOMA-B\",\n",
    "          \" HOMA-IR)\"\n",
    "        ],\n",
    "        \"date_pub\": \"1/17/2010\",\n",
    "        \"title\": \"New genetic loci implicated in fasting glucose homeostasis and their impact on type 2 diabetes risk.\",\n",
    "        \"location_within_paper\": \"FullData\",\n",
    "        \"paper_phenotype_categories\": \"Quantitative trait(s);Type 2 diabetes (T2D);Blood-related\",\n",
    "        \"journal\": \"Nat Genet\"\n",
    "      },\n",
    "      {\n",
    "        \"pmid\": 20522523,\n",
    "        \"phenotype\": \"Partial epilepsy\",\n",
    "        \"p_value\": 0.022849999999999998784,\n",
    "        \"snpid\": \"rs6083780\",\n",
    "        \"paper_phenotype_description\": \"Epilepsy (partial epilepsy)\",\n",
    "        \"date_pub\": \"6/22/2010\",\n",
    "        \"title\": \"Common genetic variation and susceptibility to partial epilepsies: a genome-wide association study.\",\n",
    "        \"location_within_paper\": \"FullScan\",\n",
    "        \"paper_phenotype_categories\": \"Neuro;Epilepsy\",\n",
    "        \"journal\": \"Brain\"\n",
    "      }\n",
    "    ],\n",
    "    \"last_curation_date\": \"8/17/12\",\n",
    "    \"replication\": [\n",
    "      {\n",
    "        \"total_samples\": 76558,\n",
    "        \"european\": 76558\n",
    "      },\n",
    "      {\n",
    "        \"total_samples\": 133661,\n",
    "        \"european\": 133661\n",
    "      }\n",
    "    ],\n",
    "    \"discovery\": [\n",
    "      {\n",
    "        \"total_samples\": 46186,\n",
    "        \"european\": 46186\n",
    "      },\n",
    "      {\n",
    "        \"total_samples\": 10380,\n",
    "        \"european\": 10380\n",
    "      }\n",
    "    ],\n",
    "    \"hupfield\": \"Jan2014\",\n",
    "    \"includes_male_female_only_analyses\": \"n\",\n",
    "    \"in_gene\": \"(ENTPD6)\",\n",
    "    \"replication_sample_description\": [\n",
    "      \"up to 76558 EA individuals\",\n",
    "      \"NR\",\n",
    "      \"133661 EA individuals\",\n",
    "      \"133661 EA individuals\"\n",
    "    ]\n",
    "  },\n",
    "  \"start\": 51447065\n",
    "} ```\n",
    "\n",
    "\n",
    "The richness of the data derives from the usage of MyVariant.info services and the high-availability of the datasets hosted by them. Further, being updated at least monthly, their databases can be guaranteed to deliver the most accurate and relevat data for specific variants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Prioritization\n",
    "\n",
    "Once annotated, variants can be prioritized for further examination by applying built-in or custom filters.  For example, the built-in filter function `rare_cancer_variant()` will identify variants with annotation that satisfies all of the below filter conditions:\n",
    "\n",
    " - filter 1: ThousandGenomeAll < 0.05 or info not available\n",
    " - filter 2: ESP6500siv2_all < 0.05 or info not available\n",
    " - filter 3: cosmic70 information is present\n",
    " - filter 4: Func_knownGene is exonic, splicing, or both\n",
    " - filter 5: ExonicFunc_knownGene is not \"synonymous SNV\"\n",
    " - filter 6: Read Depth (DP) > 10\n",
    " \n",
    "Identifying these variants with VAPr requires very little coding.  (Note that in this case, the database name and collection name *do* need to refer to existing items, since they specify the variant data that will be searched)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from VAPr import MongoDB_querying\n",
    "\n",
    "collection_name = 'My_Variant_Collection_File_One'\n",
    "db_name = 'My_Variant_Database'\n",
    "\n",
    "filter_collection = MongoDB_querying.Filters(db_name, collection_name)\n",
    "rare_cancer_variants = filter_collection.rare_cancer_variant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom filters can be implemented using the keys of the annotation dictionary and the standard [pymongo query syntax](http://api.mongodb.com/python/current/tutorial.html), developed by MongoDB, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = getattr(client, db_name)\n",
    "collection = getattr(db, collection_name)\n",
    "\n",
    "\n",
    "filtered = collection.find({\"$and\": [\n",
    "                                   {\"$or\": [{\"esp6500siv2_all\": {\"$lt\": 0.1}}, {\"esp6500siv2_all\": {\"$exists\": False}}]},\n",
    "                                   {\"$or\": [{\"func_knowngene\": \"exonic\"}, {\"func_knowngene\": \"splicing\"}]},\n",
    "                                   {\"genotype.filter_passing_reads_count\": {\"$gte\": 1}},\n",
    "                                   {\"cosmic70\": {\"$exists\": True}},\n",
    "                                   {\"1000g2015aug_all\": {\"$exists\": True}}\n",
    "                         ]})\n",
    "\n",
    "as_list = list(filtered)\n",
    "len(as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned annotation for each variant matching a filter is provided as a Python dictionary that can easily be accessed from script.  For example, the full annotation for a single variant might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rare_cancer_variants[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing a particular element of the annotation, such as determining the genomic environment of the annotated variant, can be accessed with simple Python dictionary syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rare_cancer_variants[0][\"annotype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, the list of annotation dictionaries can be loaded into a data frame in the [pandas](http://pandas.pydata.org/) Python data analysis library and then manipulated with all the numerous options provided by that package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(as_list)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Export\n",
    "\n",
    "Full or filtered sets of variants and their annotations can be exported to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rare_cancer_variants_csv = '/data/out_files/rare_vars.csv'\n",
    "\n",
    "my_writer = file_writer.FileWriter(db_name, collection_name)\n",
    "my_writer.generate_annotated_csv(rare_cancer_variants, rare_cancer_variants_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full sets of variants and their annotations can also be output to VCF using a similar but slightly more complex syntax.  Annotations from VAPr will be added to the INFO field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rare_cancer_variants_vcf = \"/data/out_files/rare_variants.vcf\"\n",
    "input_vcf_compressed = \"/data/vcf_files/test_file_one.vcf.gz\"\n",
    "filtered_variant_list = list(filtered)\n",
    "\n",
    "my_writer = file_writer.FileWriter(db_name, collection_name)\n",
    "my_writer.generate_annotated_vcf(filtered_variant_list, input_vcf_compressed, rare_cancer_variants_vcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting filtered sets of variants to VCF requires somewhat more work, as re-creating a vcf file from a list of variants requires an index file to the original file from which a filtered version will be built. Nonetheless, this can be achieved using the tabix tool from http://genometoolbox.blogspot.com/2013/11/installing-tabix-on-unix.html.\n",
    "\n",
    "**Step 1**: Download Tabix:\n",
    "\n",
    "`tar xvjf tabix-0.2.6.tar.bz2`  \n",
    "`cd tabix-0.2.6`    \n",
    "`make`    \n",
    "`export PATH=$PATH:/path_to_tabix/tabix-0.2.6`   \n",
    "\n",
    "**Step 2**: create a .vcf.gz file from original vcf:\n",
    "\n",
    "`bgzip -c file.vcf > file.vcf.gz`\n",
    "\n",
    "\n",
    "**Step 3**: run tabix on the input vcf file:\n",
    "\n",
    "`tabix -p vcf file.vcf.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "1. Wang K, Li M, Hakonarson H. ANNOVAR: functional annotation of genetic variants from high-throughput sequencing data. Nucleic Acids Res. 2010 Sep;38(16):e164. doi: 10.1093/nar/gkq603. PubMed PMID: 20601685; PubMed Central PMCID: PMC2938201.\n",
    "2. Xin J, Mark A, Afrasiabi C, Tsueng G, Juchler M, Gopal N, Stupp GS, Putman TE, Ainscough BJ, Griffith OL, Torkamani A, Whetzel PL, Mungall CJ, Mooney SD, Su AI, Wu C (2016) High-performance web services for querying gene and variant annotation. Genome Biology 17(1):1-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}